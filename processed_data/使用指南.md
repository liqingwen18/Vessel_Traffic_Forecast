# AIS船舶数据预处理工具使用指南

## 📋 概述

本工具包提供了完整的AIS（船舶自动识别系统）数据预处理功能，专门针对您的浔江船舶流量数据进行优化。

## 🚀 快速开始

### 1. 基础数据清洗（推荐）

```bash
# 处理全部数据
python data_preprocessing_fast.py

# 处理样本数据（用于测试）
python data_preprocessing_fast.py --sample 0.01

# 自定义输出目录
python data_preprocessing_fast.py --output my_results
```

### 2. 完整预处理（包含H3网格和SG滤波）

```bash
# 基础运行
python run_preprocessing.py

# 自定义参数
python run_preprocessing.py --h3_resolution 9 --interval 10min
```

### 3. 测试和验证

```bash
# 运行测试脚本
python test_preprocessing.py
```

## 📁 输出文件说明

### 基础清洗输出
- `active_ships_cleaned.csv`: 清洗后的活跃船舶数据
- `static_ships_cleaned.csv`: 静止船舶数据（锚泊、靠泊等）
- `cleaning_report.txt`: 数据清洗报告

### 完整预处理输出
- `active_ships_processed.csv`: 包含H3网格的活跃船舶数据
- `traffic_data_processed.csv`: 时间序列流量数据（含SG滤波）
- `preprocessing_report.txt`: 完整处理报告

## 🔧 主要功能

### 1. 重复记录删除
- **完全重复**: 删除MMSI、时间、位置、速度、航向完全相同的记录
- **高频刷屏**: 删除5秒内重复上报且移动距离<10米的记录

### 2. 静止船舶剔除
- **基于船速**: SOG ≤ 0.5节视为静止
- **基于状态**: 锚泊(At anchor)、靠泊(Moored)、搁浅(Aground)等状态

### 3. 数据格式转换
- **坐标转换**: 度分格式(DDMM.MMMM) → 十进制度(DD.DDDDDD)
- **速度转换**: 0.1节单位 → 节
- **航向转换**: 0.1度单位 → 度

### 4. 时间重采样（可选）
- 默认5分钟间隔重采样
- 统计每个时间窗口内的唯一船舶数量

### 5. Savitzky-Golay滤波（可选）
- 窗口长度：5
- 多项式阶数：2
- 平滑流量数据，去除噪声

### 6. H3网格化（可选）
- 默认分辨率8（约0.7km²网格）
- 支持分辨率6-10的自定义设置

## 📊 数据质量检查

工具会自动检测以下问题：
- 异常高速记录（>50节）
- 坐标范围异常
- 时间格式问题
- 缺失值统计

## ⚙️ 参数配置

### 快速清洗参数
```bash
--input: 输入文件名（默认：final_ships_in_xunjiang.csv）
--sample: 采样比例（0.0-1.0，用于测试）
--output: 输出目录（默认：processed_data）
```

### 完整预处理参数
```bash
--h3_resolution: H3网格分辨率（默认：8）
--interval: 重采样间隔（默认：5min）
--data_path: 输入数据目录（默认：data）
```

## 📈 处理结果示例

基于测试数据（0.1%样本）的处理结果：
- **原始记录数**: 12,983条
- **活跃船舶记录数**: 3,470条（26.73%）
- **静止船舶记录数**: 9,513条（73.27%）
- **唯一船舶数**: 1,091艘
- **时间跨度**: 2024年5月-11月
- **平均船速**: 22.59节

## 🔍 数据分析建议

### 1. 流量分析
- 使用`hourly_traffic_sample.csv`进行时间序列分析
- 关注高峰时段和低谷时段的流量变化
- 分析周期性模式（日、周、月）

### 2. 空间分析
- 使用H3网格数据进行空间聚类分析
- 识别高流量区域和航道
- 分析船舶密度分布

### 3. 异常检测
- 关注高速记录，可能是数据错误或特殊情况
- 分析静止船舶的分布，识别锚地和港口区域

## ⚠️ 注意事项

1. **内存使用**: 全量数据处理需要较大内存，建议16GB以上
2. **处理时间**: 1300万条记录预计需要10-30分钟处理时间
3. **磁盘空间**: 确保有足够空间存储输出文件
4. **数据备份**: 处理前建议备份原始数据

## 🛠️ 故障排除

### 常见问题
1. **内存不足**: 使用`--sample`参数先测试小样本
2. **坐标异常**: 检查原始数据的坐标格式
3. **处理缓慢**: 考虑使用快速版本`data_preprocessing_fast.py`

### 获取帮助
```bash
python data_preprocessing_fast.py --help
python run_preprocessing.py --help
```

## 📝 下一步建议

1. **先运行测试**: 使用`test_preprocessing.py`验证功能
2. **小样本试验**: 使用`--sample 0.01`处理1%数据
3. **全量处理**: 确认无误后处理全部数据
4. **结果验证**: 检查输出文件和报告
5. **后续分析**: 使用清洗后的数据进行流量分析

## 🎯 最佳实践

1. **分步处理**: 先清洗，再网格化，最后滤波
2. **参数调优**: 根据具体需求调整H3分辨率和时间间隔
3. **质量检查**: 每步都检查数据质量报告
4. **文档记录**: 保存处理参数和结果用于复现

---

**技术支持**: 如有问题，请查看生成的报告文件或联系开发团队。
